# -*- coding: utf-8 -*-
"""pipline.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PSlHSDzPVHvoIt0OR7FKKm57ItEkYVS5
"""

import pandas as pd
import numpy as np
import sklearn # scikit-learn kutubxonasi

# Onlayn dataset joylashgan manzilini ko'rsatamiaz
URL = "https://github.com/ageron/handson-ml2/blob/master/datasets/housing/housing.csv?raw=true"
df = pd.read_csv(URL)

from sklearn.model_selection import train_test_split
train_set, test_set = train_test_split(df, test_size=0.2, random_state=42)

housing = train_set.drop("median_house_value", axis=1)
housing_labels = train_set["median_house_value"].copy()

housing_num = housing.drop("ocean_proximity", axis=1)

from sklearn.base import BaseEstimator, TransformerMixin
# bizga kerak ustunlar indekslari
rooms_ix, bedrooms_ix, population_ix, households_ix = 3, 4, 5, 6

class CombinedAttributesAdder(BaseEstimator, TransformerMixin):
    def __init__(self, add_bedrooms_per_room = True):
        self.add_bedrooms_per_room = add_bedrooms_per_room
    def fit(self, X, y=None):
        return self # bizni funksiyamiz faqat transformer. estimator emas
    def transform(self, X):
        rooms_per_household = X[:, rooms_ix] / X[:, households_ix]
        population_per_household = X[:, population_ix] / X[:, households_ix]
        if self.add_bedrooms_per_room: # add_bedrooms_per_room ustuni ixtiyoriy bo'ladi
            bedrooms_per_room = X[:, bedrooms_ix] / X[:, rooms_ix]
            return np.c_[X, rooms_per_household, population_per_household, bedrooms_per_room]
        else:
            return np.c_[X, rooms_per_household, population_per_household]

from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import OneHotEncoder, StandardScaler

num_pipeline = Pipeline([
          ('imputer', SimpleImputer(strategy='median')),
          ('attribs_adder', CombinedAttributesAdder(add_bedrooms_per_room = True)),
          ('std_scaler', StandardScaler())             
])

"""Yuoqirda biz sonli ustunlar uchun konveyer yaratdik (`num_pipeline`). 

Pipeline 3 ta transformerdan iborat (`imputer`, `atrribs_adder` va `std_scaler`), umid qilamanki, ularning vazifasi endi sizga tushunarli.
Bu transformerlarga siz istalgancha nom berishingiz mumkin.

Pipeline ihsga tushrish uchun `.fit_transform()` metodiga murojaat qilamiz.
"""

num_pipeline.fit_transform(housing_num)

"""Sonli ustunlarga ishlov beruvchi konveyer tayyor, matni ustunlarchi? 

Buning uchun maxsus `ColumnTransformer` obyektiga murojaat qilamiz, bu ham pipeline bir ko'rinishi. `ColumnTransformer` ichiga biz yuqorida yasalgan `num_ipeline` ham qo'shib yuboramiz.
"""

from sklearn.compose import ColumnTransformer

num_attribs = list(housing_num)
cat_attribs = ['ocean_proximity']

full_pipeline = ColumnTransformer([
    ('num', num_pipeline, num_attribs),
    ('cat', OneHotEncoder(), cat_attribs)
])

"""Mana yakuniy, to'liq konveyer tayyor bo'ldi (`full_pipeline`). 

Konveyerni ishga tushirish uchun `.fit_transform()` metodini chaqrisih kifoya.
"""

housing_prepared = full_pipeline.fit_transform(housing)

housing_prepared[0:5,:]

